{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d414560-27a5-4e24-83d5-36d634812327",
   "metadata": {},
   "source": [
    "# requests 문법\n",
    "- select : 복수의 값을 찾아올 때, 유사리스트형태로 값을 반환 -> 반복문 사용가능\n",
    "- select_one: 단수의 값을 찾아올때\n",
    "- text : 크롤링해온 값의 문자만 남기고 싶을 때 사용\n",
    "- strip : 해당 문자 앞,뒤 빈 여백 혹은 이스케이프 시퀀스를 제거하고자 할 때 사용\n",
    "- [\\\"속성명\\\"] : [\\\"data-price\\\"]\\n\",\n",
    "- get_text(\\\" \\\", strip=True)\\n\",\n",
    "- find : (태그를 기준) 단수의 값을 찾아올 때,\\n\",\n",
    "- find_all : (태그를 기준) 복수의 값을 찾아올 때\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84b4dd-8f0b-4ef4-8be1-df37a654355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상품명은 여러개 존재\n",
    "#복수의 상품명은 공통적 특징 : product-name\n",
    "#한번의 크롤링으로 3개를 동시에 찾아올 수 있어야 한다.\n",
    "#1개의 면수에 1개 x 3개의 값을 포함할 수 있어야 한다.\n",
    "#리스트의 형태로 가져올 수 있어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ec1cf6-2ecb-4feb-a904-8e0e723e8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오프화이트 반팔 티셔츠', '나이키 러닝화', '가죽 카드 지갑']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://crawlingtest-260122.netlify.app\" \n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "title = soup.select(\".product-name\") \n",
    "\n",
    "# for t in title [:3] :\n",
    "#     print(t.get_text().strip())  #-> strip은 오직 문자열에만 => text속성으로 먼저 문자열 객체를 만들고 strip.\n",
    "\n",
    "#list로 만들기\n",
    "\n",
    "names = [t.get_text().strip()for t in title]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f50c4f-5eea-45e5-aae9-2c4b2fa071ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상품명 / 카테고리명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35279c39-b73a-4f7d-9e82-8b27eea31dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오프화이트 반팔 티셔츠 / 의류\n",
      "나이키 러닝화 / 신발\n",
      "가죽 카드 지갑 / 잡화\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://crawlingtest-260122.netlify.app\" \n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#-> 상품명과 카테고리는 형제관계인 클래스이기 때문에 부모를 찾아와야함.\n",
    "\n",
    "for card in soup.select(\".product-card\") :  #-> product-card 라는 부모밑에 product-name은 하나밖에 없으므로 select_one\n",
    "    name = card.select_one(\".product-name\").text.strip()\n",
    "    category = card.select_one(\".category\").text.strip()\n",
    "    print(f\"{name} / {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b798d-4476-44ee-90b5-5707ffd5f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상품당: 가격 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38537e9-0a28-4049-8eae-f8fce93e7df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오프화이트 반팔 티셔츠 / 89,000\n",
      "나이키 러닝화 / 129,000\n",
      "가죽 카드 지갑 / 45,000\n"
     ]
    }
   ],
   "source": [
    "#상품당 : 가격 출력!!!\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://crawlingtest-260122.netlify.app\" \n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "for card in soup.select(\".product-card\") :\n",
    "    name = card.select_one(\".product-name\").text.strip()\n",
    "    price = int(card.select_one(\".price\")[\"data-price\"])\n",
    "    # print(type(price))\n",
    "    print(f\"{name} / {price:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb8f2e-cb49-4ccc-9246-8160fc1de831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d1d9f3-a973-480d-89f6-184b033b8a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오프화이트 반팔 티셔츠 / NEW\n",
      "나이키 러닝화 / HOT\n"
     ]
    }
   ],
   "source": [
    "# NEW / HOT 배지가 있는 상품만 상품명을 크롤링해오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://crawlingtest-260122.netlify.app\" \n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "for card in soup.select(\".product-card\") :\n",
    "    badge = card.select_one(\".badge\")\n",
    "    if badge :\n",
    "        name = card.select_one(\".product-name\").text.strip()\n",
    "        print(f\"{name} / {badge.text.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f4c4ab-a6e8-4793-9a85-558fbf2c4043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오프화이트 반팔 티셔츠 / 89,000\n",
      "나이키 러닝화 / 129,000\n"
     ]
    }
   ],
   "source": [
    "# 5만원 이상의 상품의 이름만 크롤링 해오세요!!\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://crawlingtest-260122.netlify.app\" \n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "for card in soup.select(\".product-card\") :\n",
    "    price = int(card.select_one(\".price\")[\"data-price\"])\n",
    "    if price >= 50000 :\n",
    "        name = card.select_one(\".product-name\").text.strip()\n",
    "        print(f\"{name} / {price:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f50f9a-1a98-44bd-837b-9d23b48a3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': '오프화이트 반팔 티셔츠', 'category': '의류', 'price': 89000}, {'name': '나이키 러닝화', 'category': '신발', 'price': 129000}, {'name': '가죽 카드 지갑', 'category': '잡화', 'price': 45000}]\n"
     ]
    }
   ],
   "source": [
    "# 특정 사이트에 접속 데이터 수집 + 재활용 (프로토타입)\n",
    "# 수집한 상품별 상품명, 카테고리, 가격 을 하나의 딕셔너리로 만들어주시고, 해당 딕셔너리가 하나의 리스트 안에 저장될 수 있도록 해주세요.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://crawlingtest-260122.netlify.app\" \n",
    "headers = {\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\"\"\"\n",
    "[\n",
    "    {\n",
    "        \"name\": \"...\",\n",
    "        \"category\": \"...\",\n",
    "        \"price\": \"...\"\n",
    "    },\n",
    "    {},\n",
    "    {}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "items = []\n",
    "\n",
    "for card in soup.select(\".product-card\") :\n",
    "    # price = int(card.select_one(\".price\")[\"data-price\"])\n",
    "    items.append({\n",
    "        \"name\": card.select_one(\".product-name\").text.strip(),\n",
    "        \"category\": card.select_one(\".category\").text.strip(),\n",
    "        \"price\": int(card.select_one(\".price\")[\"data-price\"])\n",
    "    })\n",
    "\n",
    "print(items)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dccdd7-3c89-43eb-ba93-8ca08aea2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<p class=\"desc\">\n",
    "    여름용\n",
    "    <strong>오프화이트</strong>\n",
    "    반팔 티셔츠\n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "# desc = soup.select_one(\".desc\").text.strip() 앞.뒤쪽 영역의 빈 공백\n",
    "desc = soup.select_one(\".desc\").get_text(\" \", strip=True) # 내부 영역의 빈 공백까지도 영향\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215aaa87-1fe5-435d-86b3-a4e859cc86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<body id=\"body\">\n",
    "    <p class=\"cssstyle\">오늘의 추천 상품입니다.</p>\n",
    "    <p class=\"cssstyle\">지금 구매하면 할인!</p>\n",
    "    <p align=\"center\">이 문구는 중앙정렬 안내입니다.</p>\n",
    "    <div class=\"product-card\">\n",
    "        <h2 class=\"product-name\">나이키 러닝화</h2>\n",
    "        <p class=\"category\">신발</p>\n",
    "        <p class=\"price\" data-price=\"129000\">129,000원</p>\n",
    "    </div>\n",
    "</body>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# data = soup.find(\"p\", class_=\"cssstyle\")\n",
    "# data = soup.find(\"p\", \"cssstyle\") # class_ 생략\n",
    "# data = soup.find(\"p\", attrs={\"align\": \"center\"})\n",
    "data = soup.find(id=\"body\")\n",
    "print(data.get_text(\" \", strip=True))\n",
    "\n",
    "# datas = soup.find_all(\"p\", class_=\"cssstyle\")\n",
    "# for data in datas :\n",
    "#     print(data.get_text(\" \", strip=True))\n",
    "\n",
    "# 1) select & select_one\n",
    "# 2) find & find_all (*일반적인 사이트는 대부분 div 남발)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
